{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"stage2.ipynb","provenance":[],"collapsed_sections":["wYBY4Zm-jkg5"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"IdXIu7OUA_FF","colab_type":"code","outputId":"4a28a931-5749-4262-c7a8-854b44925d77","executionInfo":{"status":"ok","timestamp":1576102359062,"user_tz":300,"elapsed":32952,"user":{"displayName":"Chris Hu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAMgWUyxjQYL-MC80N3vWTtjEn8NKDiPddTeTXXHw=s64","userId":"12818740701110365320"}},"colab":{"base_uri":"https://localhost:8080/","height":166}},"source":["!nvidia-smi -L\n","from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n","Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wYBY4Zm-jkg5","colab_type":"text"},"source":["# Install Models"]},{"cell_type":"code","metadata":{"id":"HDydLhpOjnhg","colab_type":"code","outputId":"947ef096-1279-4cce-9f6e-384db80ce89d","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1576102456001,"user_tz":300,"elapsed":27059,"user":{"displayName":"Chris Hu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAMgWUyxjQYL-MC80N3vWTtjEn8NKDiPddTeTXXHw=s64","userId":"12818740701110365320"}}},"source":["%cd /content\n","!apt-get install protobuf-compiler python-pil python-lxml python-tk\n","!pip install Cython\n","#!pip install jupyter\n","#!pip install matplotlib\n","\n","!git clone https://github.com/tensorflow/models.git\n","\n","%cd /content/models/research\n","\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","import sys\n","sys.path.append('/content/models/research/slim')\n","\n","!python object_detection/builders/model_builder_test.py"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n","python-tk is already the newest version (2.7.16-2~18.04).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-430\n","Use 'apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  python-bs4 python-chardet python-html5lib python-olefile\n","  python-pkg-resources python-six python-webencodings\n","Suggested packages:\n","  python-genshi python-lxml-dbg python-lxml-doc python-pil-doc python-pil-dbg\n","  python-setuptools\n","The following NEW packages will be installed:\n","  python-bs4 python-chardet python-html5lib python-lxml python-olefile\n","  python-pil python-pkg-resources python-six python-webencodings\n","0 upgraded, 9 newly installed, 0 to remove and 7 not upgraded.\n","Need to get 1,818 kB of archives.\n","After this operation, 7,688 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-bs4 all 4.6.0-1 [67.9 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-chardet all 3.0.4-1 [80.3 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-webencodings all 0.5-2 [10.3 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-html5lib all 0.999999999-1 [83.6 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-lxml amd64 4.2.1-1ubuntu0.1 [1,075 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-olefile all 0.45.1-1 [33.2 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pil amd64 5.1.0-1 [328 kB]\n","Fetched 1,818 kB in 2s (1,207 kB/s)\n","Selecting previously unselected package python-bs4.\n","(Reading database ... 134983 files and directories currently installed.)\n","Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n","Unpacking python-bs4 (4.6.0-1) ...\n","Selecting previously unselected package python-pkg-resources.\n","Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python-chardet.\n","Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n","Unpacking python-chardet (3.0.4-1) ...\n","Selecting previously unselected package python-six.\n","Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n","Unpacking python-six (1.11.0-2) ...\n","Selecting previously unselected package python-webencodings.\n","Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n","Unpacking python-webencodings (0.5-2) ...\n","Selecting previously unselected package python-html5lib.\n","Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n","Unpacking python-html5lib (0.999999999-1) ...\n","Selecting previously unselected package python-lxml:amd64.\n","Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n","Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Selecting previously unselected package python-olefile.\n","Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n","Unpacking python-olefile (0.45.1-1) ...\n","Selecting previously unselected package python-pil:amd64.\n","Preparing to unpack .../8-python-pil_5.1.0-1_amd64.deb ...\n","Unpacking python-pil:amd64 (5.1.0-1) ...\n","Setting up python-pkg-resources (39.0.1-2) ...\n","Setting up python-six (1.11.0-2) ...\n","Setting up python-bs4 (4.6.0-1) ...\n","Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Setting up python-olefile (0.45.1-1) ...\n","Setting up python-pil:amd64 (5.1.0-1) ...\n","Setting up python-webencodings (0.5-2) ...\n","Setting up python-chardet (3.0.4-1) ...\n","Setting up python-html5lib (0.999999999-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.14)\n","Cloning into 'models'...\n","remote: Enumerating objects: 33176, done.\u001b[K\n","remote: Total 33176 (delta 0), reused 0 (delta 0), pack-reused 33176\u001b[K\n","Receiving objects: 100% (33176/33176), 511.87 MiB | 34.72 MiB/s, done.\n","Resolving deltas: 100% (21169/21169), done.\n","Checking out files: 100% (3188/3188), done.\n","/content/models/research\n","Traceback (most recent call last):\n","  File \"object_detection/builders/model_builder_test.py\", line 23, in <module>\n","    from object_detection.builders import model_builder\n","ModuleNotFoundError: No module named 'object_detection'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"34SQk6Lwgr4b","colab_type":"text"},"source":["# Imports"]},{"cell_type":"code","metadata":{"id":"cbhIdn4Yg3Jl","colab_type":"code","colab":{}},"source":["from __future__ import division\n","from __future__ import print_function\n","from __future__ import absolute_import\n","from __future__ import unicode_literals\n","\n","import glob\n","import tensorflow as tf\n","import numpy as np\n","import random\n","import os\n","import sys\n","\n","import time\n","\n","import numpy as np\n","\n","from math import atan, sqrt\n","from object_detection.utils import dataset_util\n","from tensorflow import keras\n","\n","!pip show tensorflow"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d4gz6FrEEEa_","colab_type":"text"},"source":["# Set Constants"]},{"cell_type":"code","metadata":{"id":"V-wf9j8tEDJV","colab_type":"code","colab":{}},"source":["import os\n","PROJECT_ROOT = \"/content/drive/My Drive/rob535\"\n","TEST_FILES = \"/content/drive/My Drive/rob535/test\"\n","TRAIN_FILES = \"/content/drive/My Drive/rob535/trainval\"\n","\n","STAGE_1 = os.path.join(PROJECT_ROOT, \"stage1\")\n","os.chdir(PROJECT_ROOT)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kMmRwJIQCEKV","colab_type":"text"},"source":["# Training\n"]},{"cell_type":"markdown","metadata":{"id":"AmHQQa3pCUoi","colab_type":"text"},"source":["## Generate Trainng Data"]},{"cell_type":"code","metadata":{"id":"VbxkjiUyDoi6","colab_type":"code","colab":{}},"source":["def rot(n):\n","    n = np.asarray(n).flatten()\n","    assert(n.size == 3)\n","\n","    theta = np.linalg.norm(n)\n","    if theta:\n","        n /= theta\n","        K = np.array([[0, -n[2], n[1]], [n[2], 0, -n[0]], [-n[1], n[0], 0]])\n","\n","        return np.identity(3) + np.sin(theta) * K + (1 - np.cos(theta)) * K @ K\n","    else:\n","        return np.identity(3)\n","\n","\n","def get_bbox(p0, p1):\n","    v = np.array([\n","        [p0[0], p0[0], p0[0], p0[0], p1[0], p1[0], p1[0], p1[0]],\n","        [p0[1], p0[1], p1[1], p1[1], p0[1], p0[1], p1[1], p1[1]],\n","        [p0[2], p1[2], p0[2], p1[2], p0[2], p1[2], p0[2], p1[2]]\n","    ])\n","    e = np.array([\n","        [2, 3, 0, 0, 3, 3, 0, 1, 2, 3, 4, 4, 7, 7],\n","        [7, 6, 1, 2, 1, 2, 4, 5, 6, 7, 5, 6, 5, 6]\n","    ], dtype=np.uint8)\n","\n","    return v, e\n","\n","\n","def check_coords(xmin, xmax, ymin, ymax):\n","    height = 1052  # Image height\n","    width = 1914  # Image width\n","\n","    if xmin < 0:\n","        xmin = 0\n","    if xmax > width:\n","        xmax = width\n","    if ymin < 0:\n","        ymin = 0\n","    if ymax > height:\n","        ymax = height\n","\n","    return xmin, xmax, ymin, ymax\n","\n","\n","def create_nparray(bbox_paths, istrain):\n","    X = np.zeros((10, 0))\n","    Y = np.zeros((2, 0))\n","    file_map = np.array([])\n","\n","    num_in = 0\n","    start = time.time()\n","    for i in range(0, len(bbox_paths)):\n","        if not i % 100:\n","            print(\"%d/%d\\t%f s\" % (i, len(bbox_paths), time.time()-start))\n","        proj = np.fromfile(bbox_paths[i].replace(\"_bbox.bin\", \"_proj.bin\"), dtype=np.float32)\n","        proj.resize([3, 4])\n","        bbox = np.fromfile(bbox_paths[i], dtype=np.float32)\n","        bbox = bbox.reshape([-1, 11])\n","        xyz = np.fromfile(bbox_paths[i].replace('_bbox.bin', '_cloud.bin'), dtype=np.float32)\n","        xyz = xyz.reshape([3, -1])\n","        uv = proj @ np.vstack([xyz, np.ones_like(xyz[0, :])])\n","        uv = uv / uv[2, :]\n","        dist = np.linalg.norm(xyz, axis=0)\n","\n","        for k, b in enumerate(bbox):\n","            file_map = np.append(file_map, bbox_paths[i])\n","            R = rot(b[0:3])\n","            t = b[3:6]\n","            sz = b[6:9]\n","\n","            vert_3D, edges = get_bbox(-sz / 2, sz / 2)\n","            vert_3D = R @ vert_3D + t[:, np.newaxis]\n","\n","            vert_2D = proj @ np.vstack([vert_3D, np.ones(vert_3D.shape[1])])\n","            vert_2D = vert_2D / vert_2D[2, :]\n","\n","            xmin = min(vert_2D[0, :])\n","            xmax = max(vert_2D[0, :])\n","            ymin = min(vert_2D[1, :])\n","            ymax = max(vert_2D[1, :])\n","\n","            xmin, xmax, ymin, ymax = check_coords(xmin, xmax, ymin, ymax)\n","            label = int(b[9]) #use 0 index\n","\n","            x_in_box = []\n","            y_in_box = []\n","            dist_box = []\n","            for j in range(0, uv.shape[1]):\n","                x = uv[0,j]\n","                y = uv[1,j]\n","                if xmin < x < xmax and ymin < y < ymax:\n","                    x_in_box.append(x)\n","                    y_in_box.append(y)\n","                    dist_box.append(dist[j])\n","\n","            if len(dist_box) < 10:\n","                #ignore if too few points (too far away)\n","                continue\n","\n","            X = np.append(X, np.zeros((10, 1)), axis=1)\n","            X[0, num_in] = xmin\n","            X[1, num_in] = xmax\n","            X[2, num_in] = ymin\n","            X[3, num_in] = ymax\n","            X[4, num_in] = min(dist_box)\n","            X[5, num_in] = max(dist_box)\n","            X[6, num_in] = np.mean(dist_box)\n","            X[7, num_in] = np.median(dist_box)\n","            X[8, num_in] = np.std(dist_box)\n","            X[9, num_in] = label\n","\n","            #outputs\n","            x_cent = sum(vert_3D[0,:])/8\n","            y_cent = sum(vert_3D[1,:])/8\n","            z_cent = sum(vert_3D[2,:])/8\n","            r = sqrt(x_cent*x_cent + y_cent*y_cent + z_cent*z_cent)\n","            theta = atan(x_cent/z_cent)\n","\n","            Y = np.append(Y, np.zeros((2,1)), axis=1)\n","            Y[0, num_in] = r\n","            Y[1, num_in] = theta\n","\n","            num_in = num_in + 1\n","\n","    if istrain:\n","        x_file = \"stage2/X_train\"\n","        y_file = \"stage2/Y_train\"\n","    else:\n","        x_file = \"stage2/X_test\"\n","        y_file = \"stage2/Y_test\"\n","\n","    np.save(x_file, X, allow_pickle=True)\n","    np.save(y_file, Y, allow_pickle=True)\n","    np.save(\"stage2/filename_map\", file_map, allow_pickle=True)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zHnQtdGsDdX8","colab_type":"code","colab":{}},"source":["bbox_path = glob.glob(os.path.join(TRAIN_FILES, \"/*/*bbox.bin\"))\n","random.shuffle(bbox_path)\n","num_test = int(0.2*len(bbox_path))\n","test_paths = bbox_path[0:num_test]\n","train_paths = bbox_path[num_test:]\n","print(num_test)\n","create_nparray(train_paths, True)\n","create_nparray(test_paths, False)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cnrKKxR8CYeN","colab_type":"text"},"source":["## Train Data"]},{"cell_type":"code","metadata":{"id":"LkXaG4k8ETwt","colab_type":"code","colab":{}},"source":["def avg_dist_error(y_true, y_pred):\n","    error = tf.math.abs(tf.math.subtract(y_true[:,0], y_pred[:,0]))\n","    return tf.math.reduce_mean(error)\n","\n","\n","def avg_angle_error(y_true, y_pred):\n","    error = tf.math.abs(tf.math.subtract(y_true[:,1], y_pred[:,1]))\n","    return tf.math.reduce_mean(error)\n","\n","def to_class_label_4(num):\n","    if num == 0 or num == 15 or num == 16 or num == 17 or num == 22:\n","        return 0\n","    elif 1 <= num <= 8:\n","        return 1\n","    elif num == 9 or num == 10 or num == 14:\n","        return 3\n","    else:\n","        return 2\n","\n","THRESHOLD = 55\n","\n","X_train_orig = np.transpose(np.load(\"stage2/X_train.npy\"))\n","Y_train_orig = np.transpose(np.load(\"stage2/Y_train.npy\"))\n","X_train = X_train_orig\n","Y_train = Y_train_orig\n","X_test = np.transpose(np.load(\"stage2/X_test.npy\"))\n","Y_test = np.transpose(np.load(\"stage2/Y_test.npy\"))\n","\n","#fix radians to degrees\n","Y_train[:, 1] = Y_train[:, 1]*180/np.pi\n","Y_test[:, 1] = Y_test[:, 1]*180/np.pi\n","\n","del_list = []\n","#remove anything > THRESHOLD\n","for i in range(0, X_train.shape[0]):\n","    if Y_train[i, 0] > THRESHOLD:\n","        del_list.append(i)\n","\n","#fix labels to 0-3\n","for i in range(0, X_train.shape[0]):\n","    X_train[i, 9] = to_class_label_4(X_train[i, 9])\n","\n","for i in range(0, X_test.shape[0]):\n","    X_test[i, 9] = to_class_label_4(X_test[i, 9])\n","\n","X_train = np.delete(X_train, del_list, axis=0)\n","Y_train = np.delete(Y_train, del_list, axis=0)\n","\n","model = keras.Sequential([\n","    keras.layers.Dense(16, input_dim=10, activation='relu'),\n","    keras.layers.Dense(64, activation='relu'),\n","    keras.layers.Dense(128, activation='relu'),\n","    keras.layers.Dense(32, activation='relu'),\n","    keras.layers.Dense(2)\n","])\n","\n","model.compile(optimizer='adam',\n","              loss='mean_squared_error',\n","              metrics=[avg_dist_error, avg_angle_error])\n","\n","model.fit(X_train, Y_train, epochs=200)\n","\n","Y_predict = model.predict(X_test)\n","\n","np.savetxt(\"stage2/Y_predict.txt\", Y_predict, fmt=\"%f\")\n","np.savetxt(\"stage2/Y_truth.txt\", Y_test, fmt=\"%f\")\n","\n","dist_errs = []\n","theta_errs = []\n","for i in range(0, Y_predict.shape[0]):\n","    if Y_test[i, 0] <= 50:\n","        dist_errs.append(Y_test[i, 0] - Y_predict[i, 0])\n","        theta_errs.append(Y_test[i, 1] - Y_predict[i, 1])\n","\n","print(np.mean(np.abs(dist_errs)))\n","print(np.mean(np.abs(theta_errs)))\n","\n","model.save(\"stage2/model.h5\")\n","\n","with open('stage2/model_architecture.json', 'w') as f:\n","    f.write(model.to_json())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D7azG4RXCkSO","colab_type":"text"},"source":["# Evaluation"]},{"cell_type":"markdown","metadata":{"id":"kCy5L2l7Cnnm","colab_type":"text"},"source":["## Preproccess Stage 1 Data"]},{"cell_type":"code","metadata":{"id":"Dw8v4RBpFJZv","colab_type":"code","colab":{}},"source":["import pickle\n","\n","def to_class_label_4(num):\n","    if num == 0 or num == 15 or num == 16 or num == 17 or num == 22:\n","        return 0\n","    elif 1 <= num <= 8:\n","        return 1\n","    elif num == 9 or num == 10 or num == 14:\n","        return 3\n","    else:\n","        return 2\n","\n","\n","def get_local_path(gdrive_path):\n","    gdrive_path = gdrive_path.split(\"/\")\n","    local_path = os.path.join(TEST_FILES,\n","                              gdrive_path[-2], gdrive_path[-1])\n","    local_path = local_path.replace(\"_compressed.jpg\", \".jpg\")\n","    return local_path\n","\n","\n","def load_data_dwight(file_path): #TODO\n","    data = np.load(file_path, allow_pickle=True)\n","    X_test = np.array(np.zeros((0,10)))\n","    filename_map = np.array([])\n","    num_in = 0\n","    for i in range(0, data.shape[0]):\n","        local_path = get_local_path(data[i][0])\n","        bbox_list = data[i][1]\n","\n","        proj = np.fromfile(local_path.replace(\"_image.jpg\", \"_proj.bin\"), dtype=np.float32)\n","        proj.resize([3, 4])\n","        xyz = np.fromfile(local_path.replace('_image.jpg', '_cloud.bin'), dtype=np.float32)\n","        xyz = xyz.reshape([3, -1])\n","        uv = proj @ np.vstack([xyz, np.ones_like(xyz[0, :])])\n","        uv = uv / uv[2, :]\n","        dist = np.linalg.norm(xyz, axis=0)\n","\n","        for bbox in bbox_list:\n","            if bbox[\"name\"] == \"car\":\n","                label = 1\n","            elif bbox[\"name\"] == \"truck\" or bbox[\"name\"] == \"bus\":\n","                label = 2\n","            elif bbox[\"name\"] == \"motorbike\" or bbox[\"name\"] == \"bicycle\":\n","                label = 3\n","            else:\n","                continue\n","\n","            xmin = bbox[\"box_points\"][0]\n","            ymin = bbox[\"box_points\"][1]\n","            xmax = bbox[\"box_points\"][2]\n","            ymax = bbox[\"box_points\"][3]\n","\n","            dist_box = []\n","            for j in range(0, uv.shape[1]):\n","                x = uv[0,j]\n","                y = uv[1,j]\n","                if xmin < x < xmax and ymin < y < ymax:\n","                    dist_box.append(dist[j])\n","\n","            if len(dist_box) < 10:\n","                #ignore if too few points (too far away)\n","                continue\n","\n","            filename_map = np.append(filename_map, local_path)\n","            X_test = np.append(X_test, np.zeros((1, 10)), axis=0)\n","\n","            X_test[num_in, 0] = xmin\n","            X_test[num_in, 1] = xmax\n","            X_test[num_in, 2] = ymin\n","            X_test[num_in, 3] = ymax\n","            X_test[num_in, 4] = min(dist_box)\n","            X_test[num_in, 5] = max(dist_box)\n","            X_test[num_in, 6] = np.mean(dist_box)\n","            X_test[num_in, 7] = np.median(dist_box)\n","            X_test[num_in, 8] = np.std(dist_box)\n","            X_test[num_in, 9] = label\n","\n","            num_in = num_in + 1\n","\n","    return X_test, filename_map\n","\n","\n","def load_data_chris(detections_file_path):\n","    detections = pickle.load( open(detections_file_path, \"rb\"))\n","    width = 1914\n","    height = 1052\n","    X_test = np.array(np.zeros((0,10)))\n","    filename_map = np.array([])\n","\n","    num_in = 0\n","    for one_image in detections:\n","        local_path = get_local_path(one_image[\"path\"])\n","        bbox = one_image[\"bbox\"]\n","\n","        proj = np.fromfile(local_path.replace(\"_image.jpg\", \"_proj.bin\"), dtype=np.float32)\n","        proj.resize([3, 4])\n","        xyz = np.fromfile(local_path.replace('_image.jpg', '_cloud.bin'), dtype=np.float32)\n","        xyz = xyz.reshape([3, -1])\n","        uv = proj @ np.vstack([xyz, np.ones_like(xyz[0, :])])\n","        uv = uv / uv[2, :]\n","        dist = np.linalg.norm(xyz, axis=0)\n","\n","        for i in range(0, len(bbox)):\n","            label = one_image[\"label\"][i]-1\n","\n","            #hopefully these are right\n","            xmin = min(bbox[i][1], bbox[i][3]) * width\n","            xmax = max(bbox[i][1], bbox[i][3]) * width\n","            ymin = min(bbox[i][0], bbox[i][2]) * height\n","            ymax = max(bbox[i][0], bbox[i][2]) * height\n","\n","            dist_box = []\n","            for j in range(0, uv.shape[1]):\n","                x = uv[0, j]\n","                y = uv[1, j]\n","                if xmin < x < xmax and ymin < y < ymax:\n","                    dist_box.append(dist[j])\n","\n","            if len(dist_box) < 10:\n","                # ignore if too few points (too far away)\n","                continue\n","\n","            filename_map = np.append(filename_map, local_path)\n","            X_test = np.append(X_test, np.zeros((1, 10)), axis=0)\n","\n","            X_test[num_in, 0] = xmin\n","            X_test[num_in, 1] = xmax\n","            X_test[num_in, 2] = ymin\n","            X_test[num_in, 3] = ymax\n","            X_test[num_in, 4] = min(dist_box)\n","            X_test[num_in, 5] = max(dist_box)\n","            X_test[num_in, 6] = np.mean(dist_box)\n","            X_test[num_in, 7] = np.median(dist_box)\n","            X_test[num_in, 8] = np.std(dist_box)\n","            X_test[num_in, 9] = label\n","\n","            num_in = num_in + 1\n","\n","    return X_test, filename_map\n","\n","\n","DWIGHT = False\n","\n","if DWIGHT:\n","    X_test, filename_map = load_data_dwight(\"stage2/detections_backup.npy\")\n","    np.save(\"stage2/filename_map_eval_dwight\", filename_map, allow_pickle=True)\n","    np.save(\"stage2/X_test_eval_dwight\", X_test, allow_pickle=True)\n","else:\n","    X_test, filename_map = load_data_chris(\"calculated_bbox-test.pkl\")\n","    np.save(\"stage2/filename_map_eval\", filename_map, allow_pickle=True)\n","    np.save(\"stage2/X_test_eval\", X_test, allow_pickle=True)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZuvAMaTPDMIp","colab_type":"text"},"source":["## Evaluate and generate CSV Files"]},{"cell_type":"code","metadata":{"id":"pakrA7d3FiVQ","colab_type":"code","colab":{}},"source":["import csv\n","\n","with open('stage2/model_architecture.json', 'r') as f:\n","    model = keras.models.model_from_json(f.read())\n","\n","model.load_weights(\"stage2/model.h5\")\n","\n","X_test = np.load(\"stage2/X_test_eval.npy\")\n","filename_map = np.load(\"stage2/filename_map_eval.npy\")\n","\n","Y_predict = model.predict(X_test)\n","np.savetxt(\"stage2/Y_predict_eval.txt\", Y_predict, fmt=\"%f\")\n","\n","#create task 1 csv\n","data_dir = TEST_FILES\n","image_files_full = glob.glob(os.path.join(data_dir, \"*/*_image.jpg\"))\n","\n","image_files = []\n","pred_dict = {} #maps filename -> closest detection\n","for i, image_file in enumerate(image_files_full):\n","    path_split = image_file.split(os.sep)\n","    image_files.append(os.path.join(path_split[-2], path_split[-1]).replace(os.sep, \"/\"))\n","    pred_dict[image_files[i]] = []\n","\n","for i in range(0, Y_predict.shape[0]):\n","    path_split = filename_map[i].split(os.sep)\n","    file = os.path.join(path_split[-2], path_split[-1]).replace(os.sep, \"/\")\n","\n","    if len(pred_dict[file]) == 0 or pred_dict[file][0][\"dist\"] > Y_predict[i, 0]:\n","        tmp = {\"dist\": Y_predict[i, 0], \"angle\": Y_predict[i, 1], \"label\": int(X_test[i, 9]),\n","               \"bbox\": [X_test[i,0], X_test[i,1], X_test[i,2], X_test[i,3]]}\n","        try:\n","            pred_dict[file][0] = tmp\n","        except IndexError:\n","            pred_dict[file].append(tmp)\n","\n","pred_labels = []\n","for image_file in image_files:\n","    if len(pred_dict[image_file]) == 0 or pred_dict[image_file][0][\"dist\"] < 50:\n","        pred_labels.append(0)\n","    else:\n","        pred_labels.append(pred_dict[image_file][0][\"label\"])\n","\n","with open(\"results-trained-resnet101-task1.csv\", \"w+\") as results_fd:\n","    results_writer = csv.writer(results_fd, delimiter=\",\", lineterminator=\"\\n\")\n","    results_writer.writerow([\"guid/image\", \"label\"])\n","    for i, image_file in enumerate(image_files):\n","        results_writer.writerow([image_file.replace(\"_image.jpg\", \"\"), pred_labels[i]])\n","\n","#Create task2 csv\n","with open(\"template.csv\") as template_fd:\n","    template_reader = csv.reader(template_fd, delimiter=\",\")\n","    image_files_task2 = []\n","    for i, row in enumerate(template_reader):\n","        if i % 2 == 0:\n","            continue\n","        else:\n","            impath = row[0].replace(\"/r\", \"_image.jpg\")\n","            image_files_task2.append(impath)\n","\n","with open(\"results-trained-resnet101-task2.csv\", \"w+\") as results_fd:\n","    results_writer = csv.writer(results_fd, delimiter=\",\", lineterminator=\"\\n\")\n","    results_writer.writerow([\"guid/image/axis\", \"value\"])\n","    for i, image_file in enumerate(image_files_task2):\n","        result_val = pred_dict[image_file]\n","        if len(result_val) != 0:\n","            results_writer.writerow([image_file.replace(\"_image.jpg\", \"\") + \"/r\",\n","                                     result_val[0][\"dist\"]])\n","            results_writer.writerow([image_file.replace(\"_image.jpg\", \"\") + \"/theta\",\n","                                     result_val[0][\"angle\"]])\n","        else:\n","            results_writer.writerow([image_file.replace(\"_image.jpg\", \"\") + \"/r\",\n","                                     25])\n","            results_writer.writerow([image_file.replace(\"_image.jpg\", \"\") + \"/theta\",\n","                                     0])\n"],"execution_count":0,"outputs":[]}]}