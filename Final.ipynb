{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsOSYOV0ryk0",
        "colab_type": "text"
      },
      "source": [
        "#Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqhnswmIqkpe",
        "colab_type": "text"
      },
      "source": [
        "##Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UikgilTAqPmO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "f6d4ea70-15f5-4d1a-9856-fcaaf4165d73"
      },
      "source": [
        "!nvidia-smi -L\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-d419a5b2-1b5a-e962-d0ba-343f870cbf80)\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjyuog81rvdc",
        "colab_type": "text"
      },
      "source": [
        "## Set File Path Constants\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo7G0K4vrf6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PROJECT_ROOT = \"/content/drive/My Drive/rob535\" #Change This\n",
        "TEST_FILES = \"/content/drive/My Drive/rob535/test\" #Change This (Path to test files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwdLudB8qqSH",
        "colab_type": "text"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txhlcc7JqnxQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "c40d5913-586f-4a6d-dc27-a48f83b23779"
      },
      "source": [
        "from tensorflow import keras\n",
        "import os\n",
        "import csv\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "os.chdir(PROJECT_ROOT)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRsnJPnvr9ob",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm646lJpqww1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "12249dd3-c44a-487e-da4e-d869fbd2b7a4"
      },
      "source": [
        "with open('stage2/model_architecture.json', 'r') as f:\n",
        "    model = keras.models.model_from_json(f.read())\n",
        "\n",
        "model.load_weights(\"stage2/model.h5\")\n",
        "\n",
        "X_test = np.load(\"stage2/X_test_eval.npy\")\n",
        "filename_map = np.load(\"stage2/filename_map_eval.npy\")\n",
        "\n",
        "Y_predict = model.predict(X_test)\n",
        "np.savetxt(\"stage2/Y_predict_eval.txt\", Y_predict, fmt=\"%f\")\n",
        "\n",
        "#create task 1 csv\n",
        "data_dir = TEST_FILES\n",
        "image_files_full = glob.glob(os.path.join(data_dir, \"*/*_image.jpg\"))\n",
        "\n",
        "image_files = []\n",
        "pred_dict = {} #maps filename -> closest detection\n",
        "for i, image_file in enumerate(image_files_full):\n",
        "    path_split = image_file.split(os.sep)\n",
        "    image_files.append(os.path.join(path_split[-2], path_split[-1]).replace(os.sep, \"/\"))\n",
        "    pred_dict[image_files[i]] = []\n",
        "\n",
        "for i in range(0, Y_predict.shape[0]):\n",
        "    path_split = filename_map[i].split(os.sep)\n",
        "    file = os.path.join(path_split[-2], path_split[-1]).replace(os.sep, \"/\")\n",
        "\n",
        "    if len(pred_dict[file]) == 0 or pred_dict[file][0][\"dist\"] > Y_predict[i, 0]:\n",
        "        tmp = {\"dist\": Y_predict[i, 0], \"angle\": Y_predict[i, 1], \"label\": int(X_test[i, 9]),\n",
        "               \"bbox\": [X_test[i,0], X_test[i,1], X_test[i,2], X_test[i,3]]}\n",
        "        try:\n",
        "            pred_dict[file][0] = tmp\n",
        "        except IndexError:\n",
        "            pred_dict[file].append(tmp)\n",
        "\n",
        "pred_labels = []\n",
        "for image_file in image_files:\n",
        "    if len(pred_dict[image_file]) == 0 or pred_dict[image_file][0][\"dist\"] < 50:\n",
        "        pred_labels.append(0)\n",
        "    else:\n",
        "        pred_labels.append(pred_dict[image_file][0][\"label\"])\n",
        "\n",
        "with open(\"stage2/results-trained-resnet101-task1.csv\", \"w+\") as results_fd:\n",
        "    results_writer = csv.writer(results_fd, delimiter=\",\", lineterminator=\"\\n\")\n",
        "    results_writer.writerow([\"guid/image\", \"label\"])\n",
        "    for i, image_file in enumerate(image_files):\n",
        "        results_writer.writerow([image_file.replace(\"_image.jpg\", \"\"), pred_labels[i]])\n",
        "\n",
        "#Create task2 csv\n",
        "with open(\"stage2/template.csv\") as template_fd:\n",
        "    template_reader = csv.reader(template_fd, delimiter=\",\")\n",
        "    image_files_task2 = []\n",
        "    for i, row in enumerate(template_reader):\n",
        "        if i % 2 == 0:\n",
        "            continue\n",
        "        else:\n",
        "            impath = row[0].replace(\"/r\", \"_image.jpg\")\n",
        "            image_files_task2.append(impath)\n",
        "\n",
        "with open(\"stage2/results-trained-resnet101-task2.csv\", \"w+\") as results_fd:\n",
        "    results_writer = csv.writer(results_fd, delimiter=\",\", lineterminator=\"\\n\")\n",
        "    results_writer.writerow([\"guid/image/axis\", \"value\"])\n",
        "    for i, image_file in enumerate(image_files_task2):\n",
        "        result_val = pred_dict[image_file]\n",
        "        if len(result_val) != 0:\n",
        "            results_writer.writerow([image_file.replace(\"_image.jpg\", \"\") + \"/r\",\n",
        "                                     result_val[0][\"dist\"]])\n",
        "            results_writer.writerow([image_file.replace(\"_image.jpg\", \"\") + \"/theta\",\n",
        "                                     result_val[0][\"angle\"]])\n",
        "        else:\n",
        "            results_writer.writerow([image_file.replace(\"_image.jpg\", \"\") + \"/r\",\n",
        "                                     25])\n",
        "            results_writer.writerow([image_file.replace(\"_image.jpg\", \"\") + \"/theta\",\n",
        "                                     0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}